{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate, Conv2D, Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
    "from keras.optimizers import Adam, Adamax, Nadam, Adadelta, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from collections import defaultdict\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "from keras.backend import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = 10\n",
    "Dir = '/home/yokoyang/PycharmProjects/untitled/896_biaozhu'\n",
    "\n",
    "train_img = pd.read_csv(Dir + '/data_imageID.csv')\n",
    "\n",
    "Image_ID = sorted(train_img.ImageId.unique())\n",
    "\n",
    "N_split = 8\n",
    "\n",
    "Patch_size = 112\n",
    "crop_size = 144\n",
    "edge_size = int((crop_size - Patch_size) / 2)\n",
    "Class_Type = 1\n",
    "\n",
    "Scale_Size = Patch_size * N_split\n",
    "get_size = 110\n",
    "smooth = 1e-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(image_id):\n",
    "    filename = os.path.join(\n",
    "        Dir, 'mix_all', '{}.npy'.format(image_id))\n",
    "    msk = np.load(filename)\n",
    "    return msk\n",
    "\n",
    "\n",
    "def get_image(image_id):\n",
    "    filename = os.path.join(\n",
    "        Dir, 'split-data', '{}.tif'.format(image_id))\n",
    "    img = tiff.imread(filename)\n",
    "    img = img.astype(np.float32) / 255\n",
    "    img_RGB = cv2.resize(img, (Scale_Size, Scale_Size))\n",
    "    return img_RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reflect_img(img):\n",
    "    reflect = cv2.copyMakeBorder(img, int(edge_size), int(edge_size), int(edge_size), int(edge_size),\n",
    "                                 cv2.BORDER_REFLECT)\n",
    "    return reflect\n",
    "\n",
    "\n",
    "def rotate_img(img, ang, size):\n",
    "    rows = size\n",
    "    cols = size\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 90 * ang, 1)\n",
    "    dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "    return dst\n",
    "\n",
    "\n",
    "def rotate_msk(msk, ang):\n",
    "    return np.rot90(msk, ang)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patch(img_id, pos=1):\n",
    "    img_ = []\n",
    "    msk_ = []\n",
    "    img = get_image(img_id)\n",
    "    img = reflect_img(img)\n",
    "    mask = get_mask(img_id)\n",
    "    for i in range(N_split):\n",
    "        for j in range(N_split):\n",
    "            y = mask[Patch_size * i:Patch_size * (i + 1), Patch_size * j:Patch_size * (j + 1)]\n",
    "            if ((pos == 1) and (np.sum(y) > 0)) or (pos == 0):\n",
    "                x_start = int(Patch_size * i)\n",
    "                x_end = int(Patch_size * (i + 1) + edge_size * 2)\n",
    "                y_start = int(Patch_size * j)\n",
    "                y_end = int(Patch_size * (j + 1) + edge_size * 2)\n",
    "                x = img[x_start:x_end, y_start:y_end, :]\n",
    "                # start rotate y and x\n",
    "                rdm = random.uniform(-2, 5)\n",
    "                if rdm > 1:\n",
    "                    ang = rdm // 1\n",
    "                    x = rotate_img(x, ang, crop_size)\n",
    "                    y = rotate_msk(y, ang)\n",
    "\n",
    "                img_.append(x)\n",
    "                msk_.append(y[:, :, None])\n",
    "\n",
    "    return img_, msk_\n",
    "\n",
    "\n",
    "def get_all_patches(pos=1):\n",
    "    img_all = []\n",
    "    msk_all = []\n",
    "    count = 0\n",
    "    for img_id in Image_ID:\n",
    "        img_, msk_ = get_patch(img_id, pos=pos)\n",
    "        if len(msk_) > 0:\n",
    "            count = count + 1\n",
    "            if count == 1:\n",
    "                img_all = img_\n",
    "                msk_all = msk_\n",
    "            else:\n",
    "                img_all = np.concatenate((img_all, img_), axis=0)\n",
    "                msk_all = np.concatenate((msk_all, msk_), axis=0)\n",
    "\n",
    "    # if pos == 1:\n",
    "    #     np.save(Dir + '/output/data_pos_%d_%d_class%d' % (crop_size, N_split, Class_Type), img_all)\n",
    "    #\n",
    "    # else:\n",
    "    #     np.save(Dir + '/output/data_%d_%d_class%d' % (crop_size, N_split, Class_Type), img_all)\n",
    "\n",
    "    return img_all, msk_all[:, :, :, 0]\n",
    "\n",
    "\n",
    "def get_normalized_patches():\n",
    "    img_all, msk_all = get_all_patches()\n",
    "    #     data = np.load(Dir + '/output/data_pos_%d_%d_class%d.npy' % (Patch_size, N_split, Class_Type))\n",
    "    img = img_all\n",
    "    msk = msk_all\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = (img - mean) / std\n",
    "    print(mean, std)\n",
    "    # print(np.mean(img), np.std(img))\n",
    "    return img, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    return -K.log(jaccard_coef(y_true, y_pred)) + binary_crossentropy(y_pred, y_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_normalize_image(img, mean=0.338318, std=0.189734):\n",
    "    img = (img - mean) / std\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet0():\n",
    "    inputs = Input((crop_size, crop_size, 3))\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "    conv1 = BatchNormalization(axis=1)(conv1)\n",
    "    conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv1)\n",
    "    conv1 = BatchNormalization(axis=1)(conv1)\n",
    "    conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(pool1)\n",
    "    conv2 = BatchNormalization(axis=1)(conv2)\n",
    "    conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv2)\n",
    "    conv2 = BatchNormalization(axis=1)(conv2)\n",
    "    conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(pool2)\n",
    "    conv3 = BatchNormalization(axis=1)(conv3)\n",
    "    conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv3)\n",
    "    conv3 = BatchNormalization(axis=1)(conv3)\n",
    "    conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(pool3)\n",
    "    conv4 = BatchNormalization(axis=1)(conv4)\n",
    "    conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv4)\n",
    "    conv4 = BatchNormalization(axis=1)(conv4)\n",
    "    conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(pool4)\n",
    "    conv5 = BatchNormalization(axis=1)(conv5)\n",
    "    conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv5)\n",
    "    conv5 = BatchNormalization(axis=1)(conv5)\n",
    "    conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "\n",
    "    up6 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_uniform')(\n",
    "        UpSampling2D(size=(2, 2))(conv5))\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(merge6)\n",
    "    conv6 = BatchNormalization(axis=1)(conv6)\n",
    "    conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv6)\n",
    "    conv6 = BatchNormalization(axis=1)(conv6)\n",
    "    conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "\n",
    "    up7 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_uniform')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(merge7)\n",
    "    conv7 = BatchNormalization(axis=1)(conv7)\n",
    "    conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv7)\n",
    "    conv7 = BatchNormalization(axis=1)(conv7)\n",
    "    conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "\n",
    "    up8 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_uniform')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(merge8)\n",
    "    conv8 = BatchNormalization(axis=1)(conv8)\n",
    "    conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv8)\n",
    "    conv8 = BatchNormalization(axis=1)(conv8)\n",
    "    conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "\n",
    "    up9 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_uniform')(\n",
    "        UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "\n",
    "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(merge9)\n",
    "    conv9 = BatchNormalization(axis=1)(conv9)\n",
    "    conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "    conv9 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_uniform')(conv9)\n",
    "    crop9 = Cropping2D(cropping=((edge_size, edge_size), (edge_size, edge_size)))(conv9)\n",
    "    conv9 = BatchNormalization(axis=1)(crop9)\n",
    "    conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, 1, n_class, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer=Nadam(lr=1e-3), loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3369439 0.19670524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 10), activation=\"sigmoid\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5536 samples, validate on 1385 samples\nEpoch 1/60\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (16, 112, 112, 1, 10) for Tensor 'conv2d_69_target:0', which has shape '(?, ?, ?, ?)'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2b4a4376d277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# model_checkpoint = ModelCheckpoint(check_point_file_name, monitor='val_acc', save_best_only=True, mode='max')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     model.fit(x_trn, y_trn, batch_size=16, epochs=60, verbose=1, shuffle=True, callbacks=[model_checkpoint],\n\u001b[0;32m---> 24\u001b[0;31m               validation_data=(x_val, y_val))\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mlast_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_point_file_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mloop_i\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1111\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1113\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1114\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (16, 112, 112, 1, 10) for Tensor 'conv2d_69_target:0', which has shape '(?, ?, ?, ?)'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "all_Image_ID = sorted(train_img.ImageId.unique())\n",
    "all_len = len(all_Image_ID)\n",
    "loop_time = all_len // get_size\n",
    "last_weight = ''\n",
    "loop_i = 0\n",
    "for i in range(loop_time):\n",
    "    Image_ID = random.sample(all_Image_ID, get_size)\n",
    "    all_Image_ID = [Image_ID2 for Image_ID2 in all_Image_ID if Image_ID2 not in Image_ID]\n",
    "    img, msk = get_normalized_patches()\n",
    "    x_trn, x_val, y_trn, y_val = train_test_split(img, msk, test_size=0.2, random_state=42)\n",
    "    y_trn = y_trn[:, :, :, None]\n",
    "    y_val = y_val[:, :, :, None]\n",
    "\n",
    "    model = get_unet0()\n",
    "    if i != 0:\n",
    "        print(\"loaded\")\n",
    "        model.load_weights(last_weight)\n",
    "\n",
    "    check_point_file_name = str(loop_i) + '_rotate_val_jaccard_coef_int_10.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(check_point_file_name, monitor='val_jaccard_coef_int', save_best_only=True,\n",
    "                                       mode='max')\n",
    "    # model_checkpoint = ModelCheckpoint(check_point_file_name, monitor='val_acc', save_best_only=True, mode='max')\n",
    "    model.fit(x_trn, y_trn, batch_size=16, epochs=60, verbose=1, shuffle=True, callbacks=[model_checkpoint],\n",
    "              validation_data=(x_val, y_val))\n",
    "    last_weight = check_point_file_name\n",
    "    loop_i += 1\n",
    "    del x_trn, x_val, y_trn, y_val, model\n",
    "\n",
    "img_last = all_len - loop_time * get_size\n",
    "print(img_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_pic(filename, img):\n",
    "    img = img.astype(np.uint8)\n",
    "    img *= 255\n",
    "    cv2.imwrite(filename, img)\n",
    "\n",
    "\n",
    "def handler_predict_result(prd, th):\n",
    "    prd_result = np.zeros((Patch_size * N_split, Patch_size * N_split, n_class)).astype(np.uint8)\n",
    "    if np.max(prd[:, :, 1]) > th:\n",
    "        \n",
    "\n",
    "    return prd_result\n",
    "\n",
    "\n",
    "def predict_id_without_msk(img_id, model, th, dir_name):\n",
    "    img = get_image_without_msk(img_id, dir_name)\n",
    "    img = post_normalize_image(img)\n",
    "    print(img.shape)\n",
    "    prd = np.zeros((Patch_size * N_split, Patch_size * N_split, n_class)).astype(np.float32)\n",
    "\n",
    "    for i in range(N_split):\n",
    "        for j in range(N_split):\n",
    "            x = img[Patch_size * i:Patch_size * (i + 1), Patch_size * j:Patch_size * (j + 1), :]\n",
    "            x = reflect_img(x)\n",
    "            tmp = model.predict(x[None, :, :, :], batch_size=4)\n",
    "            prd[Patch_size * i:Patch_size * (i + 1), Patch_size * j:Patch_size * (j + 1), :] = tmp\n",
    "    prd_result = handler_predict_result(prd, th)\n",
    "    return prd_result\n",
    "\n",
    "\n",
    "def get_image_without_msk(image_id, dir_name):\n",
    "    filename = os.path.join(\n",
    "        Dir, dir_name, '{}.tif'.format(image_id))\n",
    "    print(dir_name)\n",
    "    img = tiff.imread(filename)\n",
    "    img = img.astype(np.float32) / 255\n",
    "    img_RGB = cv2.resize(img, (Scale_Size, Scale_Size))\n",
    "    return img_RGB\n",
    "\n",
    "\n",
    "def check_predict_without_mask(model, th, dir_name, img_id=Image_ID[1], Class_Type=1):\n",
    "    msk_prd = predict_id_without_msk(img_id, model, th, dir_name)\n",
    "    img = get_image_without_msk(img_id, dir_name)\n",
    "    msk_prd = msk_prd[:, :, 0]\n",
    "    plt.figure(figsize=[21, 8])\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Training Image')\n",
    "    plt.imshow(img)\n",
    "    # img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # cv2.imwrite(\"img_result/train\" + img_id + \".tif\", img2)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.imshow(msk_prd, cmap=plt.get_cmap('gist_ncar'))\n",
    "    # cv2.imwrite(\"msk_prd.tif\", msk_prd)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    # save_result_pic(\"img_result/msk_prd_1\" + img_id + \".tif\", msk_prd)\n",
    "    # save_result_pic(\"img_result/msk_prd_2\" + img_id + \".tif\", ~msk_prd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
