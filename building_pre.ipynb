{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yokoyang/anaconda3/lib/python3.6/site-packages/tifffile/tifffile.py:7685: UserWarning: module compiled against API version 0xc but this version of numpy is 0xa\n  Functionality might be degraded or be slow.\n\n  warnings.warn('%s%s' % (e, warn))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import concatenate, Conv2D, Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
    "from keras.optimizers import Adam, Adamax, Nadam, Adadelta, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "import h5py\n",
    "import keras\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import shapely.wkt\n",
    "import shapely.affinity\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from collections import defaultdict\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "from keras.backend import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_0', '0_1', '1_2', '2_3', '3_4', '4_5', '5_6', '6_7', '7_8']\n"
     ]
    }
   ],
   "source": [
    "# Dir = '/home/yokoyang/PycharmProjects/untitled/v-shanghai'\n",
    "Dir = '/home/yokoyang/PycharmProjects/untitled/896_val'\n",
    "train_img = pd.read_csv(Dir + '/data_imageID.csv')\n",
    "\n",
    "Image_ID = sorted(train_img.ImageId.unique())\n",
    "print(Image_ID)\n",
    "\n",
    "N_split = 4\n",
    "\n",
    "Patch_size = 192\n",
    "crop_size = 224\n",
    "edge_size = int((crop_size - Patch_size) / 2)\n",
    "Class_Type = 1\n",
    "# 1200 = 300 * 4\n",
    "# size = 1024\n",
    "Scale_Size = Patch_size * N_split\n",
    "get_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(image_id):\n",
    "    filename = os.path.join(\n",
    "        Dir, 'general_building', '{}.tif'.format(image_id))\n",
    "    msk = tiff.imread(filename)\n",
    "    msk = msk.astype(np.float32) / 255\n",
    "    msk = cv2.resize(msk, (Scale_Size, Scale_Size))\n",
    "    msk_img = np.zeros([Scale_Size, Scale_Size], dtype=np.uint8)\n",
    "    msk_img[:, :] = msk[:, :, 1]\n",
    "    msk_img ^= 1\n",
    "    return msk_img\n",
    "\n",
    "\n",
    "def get_image(image_id):\n",
    "    filename = os.path.join(\n",
    "        Dir, 'split-data', '{}.tif'.format(image_id))\n",
    "    img = tiff.imread(filename)\n",
    "    img = img.astype(np.float32) / 255\n",
    "    img_RGB = cv2.resize(img, (Scale_Size, Scale_Size))\n",
    "    return img_RGB\n",
    "\n",
    "\n",
    "def reflect_img(img):\n",
    "    reflect = cv2.copyMakeBorder(img, int(edge_size), int(edge_size), int(edge_size), int(edge_size),\n",
    "                                 cv2.BORDER_REFLECT)\n",
    "    return reflect\n",
    "\n",
    "\n",
    "def rotate_img(img, ang, size):\n",
    "    rows = size\n",
    "    cols = size\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 90 * ang, 1)\n",
    "    dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "    return dst\n",
    "\n",
    "\n",
    "def rotate_msk(msk, ang):\n",
    "    return np.rot90(msk, ang)\n",
    "\n",
    "\n",
    "def get_patch(img_id, pos=1):\n",
    "    img_ = []\n",
    "    msk_ = []\n",
    "    img = get_image(img_id)\n",
    "    img = reflect_img(img)\n",
    "    mask = get_mask(img_id)\n",
    "    for i in range(N_split):\n",
    "        for j in range(N_split):\n",
    "            y = mask[Patch_size * i:Patch_size * (i + 1), Patch_size * j:Patch_size * (j + 1)]\n",
    "            if ((pos == 1) and (np.sum(y) > 0)) or (pos == 0):\n",
    "                x_start = int(Patch_size * i)\n",
    "                x_end = int(Patch_size * (i + 1) + edge_size * 2)\n",
    "                y_start = int(Patch_size * j)\n",
    "                y_end = int(Patch_size * (j + 1) + edge_size * 2)\n",
    "                x = img[x_start:x_end, y_start:y_end, :]\n",
    "                # start rotate y and x\n",
    "                rdm = random.uniform(-2, 5)\n",
    "                if rdm > 1:\n",
    "                    ang = rdm // 1\n",
    "                    x = rotate_img(x, ang, crop_size)\n",
    "                    y = rotate_msk(y, ang)\n",
    "                    # print(x.shape)\n",
    "                    # print(y.shape)\n",
    "\n",
    "                img_.append(x)\n",
    "                msk_.append(y[:, :, None])\n",
    "\n",
    "    return img_, msk_\n",
    "\n",
    "\n",
    "def get_all_patches(pos=1):\n",
    "    img_all = []\n",
    "    msk_all = []\n",
    "    count = 0\n",
    "    for img_id in Image_ID:\n",
    "        img_, msk_ = get_patch(img_id, pos=pos)\n",
    "        if len(msk_) > 0:\n",
    "            count = count + 1\n",
    "            if count == 1:\n",
    "                img_all = img_\n",
    "                msk_all = msk_\n",
    "            else:\n",
    "                img_all = np.concatenate((img_all, img_), axis=0)\n",
    "                msk_all = np.concatenate((msk_all, msk_), axis=0)\n",
    "\n",
    "    # if pos == 1:\n",
    "    #     np.save(Dir + '/output/data_pos_%d_%d_class%d' % (crop_size, N_split, Class_Type), img_all)\n",
    "    #\n",
    "    # else:\n",
    "    #     np.save(Dir + '/output/data_%d_%d_class%d' % (crop_size, N_split, Class_Type), img_all)\n",
    "\n",
    "    return img_all, msk_all[:, :, :, 0]\n",
    "\n",
    "\n",
    "def get_normalized_patches():\n",
    "    img_all, msk_all = get_all_patches()\n",
    "    #     data = np.load(Dir + '/output/data_pos_%d_%d_class%d.npy' % (Patch_size, N_split, Class_Type))\n",
    "    img = img_all\n",
    "    msk = msk_all\n",
    "    mean = np.mean(img)\n",
    "    std = np.std(img)\n",
    "    img = (img - mean) / std\n",
    "    print(mean, std)\n",
    "    print(np.mean(img), np.std(img))\n",
    "    return img, msk\n",
    "\n",
    "# In predicting testing dataset, need to use the same mean and std in preprocessing training data\n",
    "def post_normalize_image(img, mean=0.338318, std=0.189734):\n",
    "    img = (img - mean) / std\n",
    "    return img\n",
    "\n",
    "def save_result_pic(filename, img):\n",
    "    img = img.astype(np.uint8)\n",
    "    img *= 255\n",
    "    cv2.imwrite(filename, img)\n",
    "    \n",
    "def predict_id(img_id, model, th):\n",
    "    img = get_image(img_id)\n",
    "    img = post_normalize_image(img)\n",
    "    print(img.shape)\n",
    "    prd = np.zeros((Patch_size * N_split, Patch_size * N_split, 1)).astype(np.float32)\n",
    "\n",
    "    for i in range(N_split):\n",
    "        for j in range(N_split):\n",
    "            x = img[Patch_size * i:Patch_size * (i + 1), Patch_size * j:Patch_size * (j + 1), :]\n",
    "            x = reflect_img(x)\n",
    "            tmp = model.predict(x[None, :, :, :], batch_size=4)\n",
    "            prd[Patch_size * i:Patch_size * (i + 1), Patch_size * j:Patch_size * (j + 1)] = tmp\n",
    "    prd_result = prd > th\n",
    "    return prd_result, prd\n",
    "\n",
    "def check_predict_without_mask(model, th, img_id=Image_ID[1], Class_Type=1):\n",
    "    msk_prd, row = predict_id(img_id, model, th)\n",
    "    img = get_image(img_id)\n",
    "    msk_prd = msk_prd[:, :, 0]\n",
    "    plt.figure(figsize=[21, 8])\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Training Image')\n",
    "    plt.imshow(img)\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"img_result/train\"+img_id+\".tif\", img2)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.imshow(msk_prd, cmap=plt.get_cmap('gist_ncar'))\n",
    "    # cv2.imwrite(\"msk_prd.tif\", msk_prd)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    save_result_pic(\"img_result/msk_prd_1\"+img_id+\".tif\", msk_prd)\n",
    "    save_result_pic(\"img_result/msk_prd_2\"+img_id+\".tif\", ~msk_prd)\n",
    "    \n",
    "    \n",
    "def check_predict(model, th, img_id=Image_ID[1], Class_Type=1):\n",
    "    msk_prd, row = predict_id(img_id, model, th)\n",
    "    img = get_image(img_id)\n",
    "    msk_prd = msk_prd[:, :, 0]\n",
    "    msk = get_mask(img_id)\n",
    "    plt.figure(figsize=[21, 8])\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Training Image')\n",
    "    plt.imshow(img)\n",
    "    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(\"img_result/train\"+img_id+\".tif\", img2)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Training Mask')\n",
    "    plt.imshow(msk, cmap=plt.get_cmap('gist_ncar'))\n",
    "    # cv2.imwrite(\"msk.tif\", msk)\n",
    "    save_result_pic(\"img_result/ground_truth\"+img_id+\".tif\", msk)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Predicted Mask')\n",
    "    plt.imshow(msk_prd, cmap=plt.get_cmap('gist_ncar'))\n",
    "    # cv2.imwrite(\"msk_prd.tif\", msk_prd)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    save_result_pic(\"img_result/msk_prd_1\"+img_id+\".tif\", msk_prd)\n",
    "    save_result_pic(\"img_result/msk_prd_2\"+img_id+\".tif\", ~msk_prd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smooth = 1e-12\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "    return -K.log(jaccard_coef(y_true, y_pred)) + binary_crossentropy(y_pred, y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet0():\n",
    "    #     Patch_size = 224\n",
    "    inputs = Input((crop_size, crop_size, 3))\n",
    "\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = BatchNormalization(axis=1)(conv1)\n",
    "    conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "    conv1 = Conv2D(32, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    conv1 = BatchNormalization(axis=1)(conv1)\n",
    "    conv1 = keras.layers.advanced_activations.ELU()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = BatchNormalization(axis=1)(conv2)\n",
    "    conv2 = keras.layers.advanced_activations.ELU()(conv2)    \n",
    "    conv2 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    conv2 = BatchNormalization(axis=1)(conv2)\n",
    "    conv2 = keras.layers.advanced_activations.ELU()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = BatchNormalization(axis=1)(conv3)\n",
    "    conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "    conv3 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    conv3 = BatchNormalization(axis=1)(conv3)\n",
    "    conv3 = keras.layers.advanced_activations.ELU()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = BatchNormalization(axis=1)(conv4)\n",
    "    conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "    conv4 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    conv4 = BatchNormalization( axis=1)(conv4)\n",
    "    conv4 = keras.layers.advanced_activations.ELU()(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = BatchNormalization( axis=1)(conv5)\n",
    "    conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "    conv5 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    conv5 = BatchNormalization(axis=1)(conv5)\n",
    "    conv5 = keras.layers.advanced_activations.ELU()(conv5)\n",
    "        \n",
    "    up6 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv5))\n",
    "    merge6 = concatenate([conv4, up6], axis=3)\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = BatchNormalization(axis=1)(conv6)\n",
    "    conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "    conv6 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    conv6 = BatchNormalization(axis=1)(conv6)\n",
    "    conv6 = keras.layers.advanced_activations.ELU()(conv6)\n",
    "\n",
    "    up7 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = BatchNormalization(axis=1)(conv7)\n",
    "    conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "    conv7 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    conv7 = BatchNormalization(axis=1)(conv7)\n",
    "    conv7 = keras.layers.advanced_activations.ELU()(conv7)\n",
    "    \n",
    "    up8 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = BatchNormalization( axis=1)(conv8)\n",
    "    conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "    conv8 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    conv8 = BatchNormalization(axis=1)(conv8)\n",
    "    conv8 = keras.layers.advanced_activations.ELU()(conv8)\n",
    "\n",
    "    up9 = Conv2D(32, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "        UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = BatchNormalization(axis=1)(conv9)\n",
    "    conv9 = keras.layers.advanced_activations.ELU()(conv9)    \n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = BatchNormalization(axis=1)(conv9)\n",
    "    conv9 = keras.layers.advanced_activations.ELU()(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "    cropping_2d = Cropping2D(cropping=((edge_size, edge_size), (edge_size, edge_size)),\n",
    "                             input_shape=(int(crop_size), int(crop_size), 3))(conv10)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=cropping_2d)\n",
    "    model.compile(optimizer=Nadam(lr=1e-3), loss=jaccard_coef_loss, metrics=['binary_crossentropy', jaccard_coef_int])\n",
    "    # model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "model = get_unet0()\n",
    "model.load_weights('/home/yokoyang/PycharmProjects/untitled/me/0_rotate_val_jaccard_coef_int_building.hdf5')\n",
    "img_id = \"hi2\"\n",
    "check_predict_without_mask(model, 0.5, img_id=img_id, Class_Type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0\n(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_1\n(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n1_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n2_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n3_4\n(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n4_5\n(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_6\n(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n6_7\n(768, 768, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 768, 1)\nTrue\n7_8\n"
     ]
    }
   ],
   "source": [
    "model = get_unet0()\n",
    "model.load_weights('/home/yokoyang/PycharmProjects/untitled/me/0_rotate_val_jaccard_coef_int_building.hdf5')\n",
    "for d in range(9):\n",
    "    img_id = Image_ID[d]\n",
    "    check_predict(model, 0.5, img_id=img_id, Class_Type=1)\n",
    "    print(img_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = tiff.imread(\"/home/yokoyang/PycharmProjects/untitled/biaozhu/general_building/1_4.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= np.array(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
